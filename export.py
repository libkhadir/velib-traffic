import findspark
from pyspark.sql import SparkSession, SQLContext
from pyspark import SparkContext
import os
import numpy
import pandas as pd
import sqlite3
from pyspark.sql import functions
import matplotlib.pyplot as plt
import seaborn as sn
from datetime import date, timedelta

data = pd.read_csv('tmp.csv')
data = data.drop(['minute'], axis=1)

data['availability'] = (data['bikes'] + data['Ebikes']) / data['slots']

sn.set()


station_code = 10107
plt.figure(figsize=(14,9))
days=['Lundi', 'Mardi', 'Mercredi', 'Jeudi', 'Vendredi', 'Samedi', 'Dimanche']
for k in range(2, 9):
  currentDate = now - timedelta(days=k)
  value = str(currentDate)
  print('plotting date ', value)
  day=int(value.split('-')[2])
  print('selected day ', day)
  data_sub_station = data.loc[(data['code'] == station_code) & (data['day'] == day), ['hour', 'availability']]
  data_sub_station = data_sub_station.sort_values('hour')
  hours = numpy.asarray([[x, x+1] for x in range(23)]).flatten()
  avail = numpy.asarray([[data_sub_station.values[i, 1], data_sub_station.values[i, 1]] for i in range(23)]).flatten()

  plt.plot(hours, avail, label=days[currentDate.weekday()])
  plt.xlabel("Heures")
  plt.ylabel("Disponibilit√© (%)")
  plt.legend()
  plt.savefig('export.png')
  
print('process done')
